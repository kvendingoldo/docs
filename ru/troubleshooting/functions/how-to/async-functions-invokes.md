# Как работать с облачными функциями асинхронно


## Описание сценария {#case-description}

* Необходимо реализовать асинхронный вызов облачной функции;
* Необходимо закрыть соединение и отдать ответ функции, не дожидаясь окончания работы облачной функции;
* Необходимо сделать так, чтобы функция работала более 10 минут.

## Решение {#case-resolution}

Напрямую реализовать асинхронные вызовы в {{ sf-name }} не получится - пока контейнер {{ serverless-containers-name }} или облачная функция выполняются, они не могут вернуть HTTP-ответ. Как только контейнер или функция вернут ответ, их выполнение завершается.

В качестве альтернативного сценария реализовать такой пайплайн возможно при помощи сервисов {{ api-gw-name }} и {{ yds-name }}.

1. Cоздайте шлюз {{ api-gw-name }} в качестве обработчика вебхука, к которому будет [подключен поток данных {{ yds-name }}](../../../api-gateway/concepts/extensions/datastreams.md).
1. Настройте [триггер для потока данных](../../../functions/concepts/trigger/data-streams-trigger.md), который будет вызывать контейнер или функцию.

В этом случае шлюз {{ api-gw-name }} вернет код ответа `HTTP 200 OK`, а контейнер или функция асинхронно обработают вызов.

{% note warning %}

Выполнение кода внутри контейнера {{ serverless-containers-name }} или облачной функции не может выполняться дольше 10 минут, в том числе с использованием триггеров. Мы пишем об этом [в документации сервисов](../../../serverless-containers/concepts/limits.md).

{% endnote %}

Если есть возможность разбить вычисление на несколько вызовов, вы можете собрать асинхронный конвейер: когда первый вызов производит вычисления и вызывает следующую стадию через тот же самый поток данных {{ yds-name }}. Однако следует учитывать, что в этом случае второй вызов может быть обработан в другом экземпляре контейнера или облачной функции.